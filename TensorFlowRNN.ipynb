{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "get_ipython().magic('matplotlib inline')\n",
    "\n",
    "#import the data from MapR-FS\n",
    "df = pd.read_csv(\"./part-00000-01a04734-16e3-4958-b21c-f2469fc7af65.csv\").sort_values(['TimeStamp'], ascending=True).reset_index()\n",
    "df.drop(['::[scararobot]Ax_J1.PositionCommand','::[scararobot]Ax_J1.TorqueFeedback','::[scararobot]Ax_J2.PositionCommand','::[scararobot]Ax_J2.TorqueFeedback','::[scararobot]Ax_J3.TorqueFeedback','::[scararobot]Ax_J6.TorqueFeedback','::[scararobot]ScanTimeAverage','::[scararobot]Ax_J6.PositionCommand','::[scararobot]Ax_J3.PositionCommand','index'], axis=1, inplace=True)\n",
    "df['TimeStamp']=pd.to_datetime(df['TimeStamp'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot some of the columns to get an idea of the trends over time\n",
    "df.plot(x=\"TimeStamp\", y=\"::[scararobot]Ax_J1.ActualPosition\", kind=\"line\")\n",
    "df.plot(x=\"TimeStamp\", y=[\"::[scararobot]Ax_J1.ActualPosition\",\"::[scararobot]Ax_J3.TorqueCommand\"], kind=\"line\")\n",
    "df.plot(x=\"TimeStamp\", y=[\"::[scararobot]CS_Cartesian.ActualPosition[0]\",\"::[scararobot]CS_Cartesian.ActualPosition[1]\"], kind=\"line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rows that are all zeros\n",
    "df1 = df[df[\"::[scararobot]speed\"] != 0].set_index('TimeStamp')   \n",
    "print (len(df1))\n",
    "\n",
    "#create a new column that will be our feature variable for our model\n",
    "#df1['total']=df1.sum(axis=1)\n",
    "df1['Total']= df1.select_dtypes(include=['float64','float32']).apply(lambda row: np.sum(row),axis=1)\n",
    "\n",
    "#convert into a time series object\n",
    "ts = pd.Series(df1['Total'])\n",
    "ts.plot(c='b', title='RW Total Sensor Aggregation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data and inputs for our TF model\n",
    "num_periods = 100\n",
    "f_horizon = 1       #number of periods into the future we are forecasting\n",
    "TS = np.array(ts)   #convert time series object to an array\n",
    "print (TS[0:10])\n",
    "print (len(TS))\n",
    "\n",
    "#create our training input data set \"X\"\n",
    "x_data = TS[:(len(TS)-(len(TS) % num_periods))]\n",
    "print (x_data[0:5])\n",
    "x_batches = x_data.reshape(-1, num_periods, 1)\n",
    "print (len(x_batches))\n",
    "print (x_batches.shape)\n",
    "#print (x_batches[0:3])\n",
    "\n",
    "#create our training output dataset \"y\"\n",
    "y_data = TS[1:(len(TS)-(len(TS) % num_periods))+f_horizon]\n",
    "#print (y_data)\n",
    "#print (len(y_data))\n",
    "#y_data = TS[(num_periods+(f_horizon-1))::(num_periods)]\n",
    "print (y_data)\n",
    "print (len(y_data))\n",
    "y_batches = y_data.reshape(-1, num_periods, 1)\n",
    "print (len(y_batches))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create our test X and y data\n",
    "def test_data(series,forecast,num_periods):\n",
    "    test_x_setup = series[-(num_periods + forecast):]\n",
    "    testX = test_x_setup[:num_periods].reshape(-1, num_periods, 1)\n",
    "    testY = TS[-(num_periods):].reshape(-1, num_periods, 1)\n",
    "    return testX,testY\n",
    "\n",
    "X_test, Y_test = test_data(TS,f_horizon,num_periods)\n",
    "print (X_test.shape)\n",
    "print (X_test[:,(num_periods-1):num_periods])\n",
    "print (Y_test.shape)\n",
    "print (Y_test[:,(num_periods-1):num_periods])\n",
    "\n",
    "#import tensorflow libraries\n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "import tensorflow.contrib.learn as tflearn\n",
    "import tensorflow.contrib.layers as tflayers\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "import tensorflow.contrib.metrics as metrics\n",
    "import tensorflow.contrib.rnn as rnn\n",
    "\n",
    "#set up our TF model parameters\n",
    "\n",
    "tf.reset_default_graph()   #We didn't have any previous graph objects running, but this would reset the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = 1            #number of vectors submitted\n",
    "hidden = 100          #number of neurons we will recursively work through, can be changed to improve accuracy\n",
    "output = 1            #number of output vectors\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, num_periods, inputs], name = \"X\")   #create variable objects\n",
    "y = tf.placeholder(tf.float32, [None, num_periods, output], name = \"y\")\n",
    "\n",
    "\n",
    "basic_cell = tf.contrib.rnn.BasicRNNCell(num_units=hidden, activation=tf.nn.relu)   #create our RNN object\n",
    "rnn_output, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)               #choose dynamic over static\n",
    "\n",
    "learning_rate = 0.001   #small learning rate so we don't overshoot the minimum\n",
    "#tf.app.flags.DEFINE_float('learning_rate', 0.001, 'Initial learning rate.')\n",
    "\n",
    "stacked_rnn_output = tf.reshape(rnn_output, [-1, hidden])           #change the form into a tensor\n",
    "stacked_outputs = tf.layers.dense(stacked_rnn_output, output)        #specify the type of layer (dense)\n",
    "outputs = tf.reshape(stacked_outputs, [-1, num_periods, output])          #shape of results\n",
    " \n",
    "loss = tf.reduce_sum(tf.square(outputs - y),name='loss')    #define the cost function which evaluates the quality of our model\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)          #gradient descent method\n",
    "training_op = optimizer.minimize(loss)          #train the result of the application of the cost_function                                 \n",
    "\n",
    "init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100     #number of iterations or training cycles, includes both the FeedFoward and Backpropogation\n",
    "saver = tf.train.Saver()   #we are going to save the model\n",
    "DIR=\"./rwTFmodel\"  #path where the model will be saved\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for ep in range(epochs):\n",
    "        sess.run(training_op, feed_dict={X: x_batches, y: y_batches})\n",
    "        if ep % 10 == 0:\n",
    "            mse = loss.eval(feed_dict={X: x_batches, y: y_batches})\n",
    "            print(ep, \"\\tMSE:\", mse) \n",
    "            \n",
    "    y_pred = sess.run(outputs, feed_dict={X: X_test})\n",
    "    print(y_pred[:,(num_periods-1):num_periods])\n",
    "    saver.save(sess, os.path.join(DIR,\"RWsensorTFmodel\"),global_step = epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot our test y data and our y-predicted forecast\n",
    "plt.title(\"Forecast vs Actual\", fontsize=14)\n",
    "plt.plot(pd.Series(np.ravel(Y_test)), \"bo\", markersize=10, label=\"Actual\")\n",
    "#plt.plot(pd.Series(np.ravel(Y_test)), \"w*\", markersize=10)\n",
    "plt.plot(pd.Series(np.ravel(y_pred)), \"r.\", markersize=10, label=\"Forecast\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xlabel(\"Time Periods\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
